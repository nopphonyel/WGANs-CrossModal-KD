

|  Select   | Name     | Implemented? | Method                                              |                                                                 Paper Link                                                                  | Available Date |
|:---------:|:---------|:------------:|-----------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------:|:--------------:|
| **MUST**  | Baseline |    **Y**     | basic model with softmax loss                       |                                                                      â€”                                                                      |       -        |
|   **Y**   | Logits   |    **Y**     | mimic learning via regressing logits                |                              [paper](http://papers.nips.cc/paper/5484-do-deep-nets-really-need-to-be-deep.pdf)                              |      2014      |
|   **Y**   | ST       |    **Y**     | soft target                                         |                                                [paper](https://arxiv.org/pdf/1503.02531.pdf)                                                |      2015      |
|   **Y**   | AT       |    **Y**     | attention transfer                                  |                                                [paper](https://arxiv.org/pdf/1612.03928.pdf)                                                |      2017      |
|   **Y**   | AFD      |    **Y**     | attention feature distillation                      |                                              [paper](https://openreview.net/pdf?id=ryxyCeHtPB)                                              |      2020      |
|   **Y**   | CRD      |    **Y**     | contrastive representation distillation             |                                              [paper](https://openreview.net/pdf?id=SkgpBJrtvS)                                              |      2020      |
| **50/50** | DKMF     |      -       | Distilling Knowledge by Mimicking Features          |                                                                   [paper]                                                                   |      2021      |
| **50/50** | CRCD     |      -       | Complementary Relation Contrastive Distillation     |                                                                   [paper]                                                                   |      2021      |
|   **N**   | WCoRD    |      -       | Wasserstein Contrastive Representation Distillation | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Wasserstein_Contrastive_Representation_Distillation_CVPR_2021_paper.pdf) |      2021      |
